\documentclass[a4paper,english,12pt]{article}
\input{preamble}

\title{DAT-510 Assignment 1}
\author{Christian Stigen}
\date{UiS, September \nth{18}, 2017}

\begin{document}
\maketitle

% TODO: Look into MEET IN THE MIDDLE attack!! At least mention it.

\begin{abstract}
  This report presents procedures and results for recovering plaintexts and keys
  for two cipher systems --- The classical \textit{Vigenère polyalphabetic}
  substitution cipher, and the educational \textit{Simplified DES} (SDES) symmetric cipher.
%
  The Vigenère plaintext was deciphered using the \textit{Kasiski method} for
  finding key-lengths, while the individual Caesar cipher alphabets were found
  by \textit{Kerckhoffs method}: Using alphabet shifts with the highest English
  letter frequency correlation. Recombining the shifted alphabets produced the
  plaintext directly, while the key was found by simply decrypting the
  ciphertext with the plaintext as key.
%
  The SDES and TripleSDES keys were found through brute-force. The 20-bit
  TripleSDES key was found in less than 50 milliseconds by decomposing the
  decryption function and creating two separate lookup tables and encoding key
  candidates in a memory efficient bitset. Keys that did not produce
  all-printable ASCII characters were discarded.
\end{abstract}

\section{Part I --- Polyalphabetic ciphers}

Below is the raw and formatted plaintext message recovered from the Vigenère
cipher \cite{wiki:vigenere, wiki:polyalphabetic}. Spaces were added to highlight
the coincidence with the length of the key \texttt{TSHTAD}.

\begin{verbatim}
CRYPTO GRAPHY CANBES TRONGO RWEAKC RYPTOG RAPHIC STRENG
THISME ASURED INTHET IMEAND RESOUR CESITW OULDRE QUIRET
ORECOV ERTHEP LAINTE XTTHER ESULTO FSTRON GCRYPT OGRAPH
YISCIP HERTEX TTHATI SVERYD IFFICU LTTODE CIPHER WITHOU
TPOSSE SSIONO FTHEAP PROPRI ATEDEC ODINGT OOLHOW DIFFIC
ULTGIV ENALLO FTODAY SCOMPU TINGPO WERAND AVAILA BLETIM
EEVENA BILLIO NCOMPU TERSDO INGABI LLIONC HECKSA SECOND
ITISNO TPOSSI BLETOD ECIPHE RTHERE SULTOF STRONG CRYPTO
GRAPHY BEFORE THEEND OFTHEU NIVERS E
\end{verbatim}

\textit{Cryptography can be strong or weak. Cryptographic strength is measured
in the time and resources it would require to recover the plaintext.  The
result of strong cryptography is ciphertext that is very difficult to decipher
without possession of the appropriate decoding tool. How difficult given all of
today's computer power and available time, even a billion computers doing a
billion checks a second, it is not possible to decipher the result of strong
cryptography before the end of the universe.}

\subsection{Strategy}

The strategy was first to find the key length using the Kasiski method
\cite{dalkilic2000interactive, wiki:kasiski.examination}, and then use
frequency analysis to find each individual monoalphabet required to recover
the plaintext.

It is important to note that the goal was solely to decipher the given
ciphertext, not to make a general program to solve all Vigenère ciphers.

I will now describe each step in more detail.

\subsection{Finding the key length}

The very first step was to find repeated substrings in the ciphertext. A repeat
section of the ciphertext could mean that it was encrypted using the same part
of the key. In other words, by finding enough of these, it should be possible
to guess the key length.

Performing such a search was straight-forward: The problem description stated
that the key length would not be more than ten letters, so I iterated through
the ciphertext with a moving window of decreasing lengths from ten and down to
four.  Whenever I found a repeat, I recorded the distance between them. Below
are excerpts from the \texttt{vigenere.py} program output.

\begin{verbatim}
Looking for repeated substrings with lengths [4, 10]:

  Found 'VJFITRZJHI' at   0, 378 distance 378
  Found 'JFITRZJHIH' at   1, 379 distance 378
  Found 'FITRZJHIHB' at   2, 380 distance 378
  ...
  Found 'UVFPXM'     at 259, 301 distance  42
  Found 'VJFIT'      at   0, 378 distance 378
  Found 'JFITR'      at   1, 379 distance 378
  Found 'FITRZ'      at   2, 380 distance 378
  ...
  Found 'MHVLS'      at 192, 342 distance 150
  Found 'UVFPX'      at 259, 301 distance  42
  Found 'VFPXM'      at 260, 302 distance  42
  ...
  Found 'UDLM'       at 282, 348 distance  66
\end{verbatim}

Next, I looked at the recorded distances, trying to find common factors. Of
course, many of the repeated substrings could have been mere coincidences.
Fortunatley, for this ciphertext, all the distances contained common factors.

\begin{verbatim}
Attempting to deduce key length:

  Set of distances: 378 66 42 150
  Common factors:   2 3
  Proposed length:  2*3 = 6
\end{verbatim}

The idea here is that since the key is repeated over the ciphertext, each
duplicate substring would represent the same passage of plaintext. Because of
the constant key length, each distance should then be a multiple of the key
length. Therefore I factorized each distance and threw away those that were not
common to all distances.

Now that I had a possible key length, I organized the ciphertext in columns
with the same width as the key length.

\begin{verbatim}
Finding monoalphabetic ciphers. Ciphertext arranged in
6 columns is:

  VJFITR
  ZJHIHB
  VSUUEV
  MJVGGR
  KOLTKF
  ......

  First column: VZVMKKKLMTBBKVHJHXEQXYZHRAMLBE...
\end{verbatim}

The insight here is that if the correct key length has been found, all the
letters in the same column would have been encrypted with the same key letter.
As can be seen in the program output above, I arranged the text into a column,
and then extracted the vertical columns of text. Each such column should then
correspond to a single Caesar cipher\footnote{This assumes that the Vigenère
table does not use scrambled alphabets; each alphabet is written in the same
order, and shifted exactly once per key letter.}.

To break each Caesar cipher, I compared their relative letter frequencies with
those found in English texts. To find how closely they correlate, or match each
other, I calculated the \textit{normalized index of coincidence}
\cite{wiki:coincidence}. I then shifted each column alphabetically and
calculated its correlation with the English frequency distribution.  A
\textit{shift} here means that all As become Bs, all Bs become Cs and so on.

After iterating through all 25 possible shifts, I chose the shift that produced
the highest correlation. This is called \textit{Kerckhoffs' method}
\cite{wiki:vigenere}. The best correlations (or normalized index of
coincidence) is shown in the program output below.

\begin{verbatim}
Frequency analysis:
Shifts alphabets for each column to find the best coincidence
match

  Column 0 length 70: best match 0.058826 with  7 shifts
  Column 1 length 69: best match 0.064844 with  8 shifts
  Column 2 length 69: best match 0.065840 with 19 shifts
  Column 3 length 69: best match 0.061286 with  7 shifts
  Column 4 length 69: best match 0.067704 with  0 shifts
  Column 5 length 69: best match 0.057107 with 23 shifts
\end{verbatim}

The correlation function, taken from \cite{wiki:coincidence}, was
\[
  \sum_{i=1}^{c} n_i f_i
\]
where $n_i$ is the frequency of the $i$th letter in the column, and $f_i$ the
frequency of the \textit{same letter} in normal English texts. The point is to
match the frequency distribution pattern. This is best shown in figure
\vref{figure:freqs}.

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{freqs.pdf}
  \caption{The lower plot shows how the column letter frequency is better
  correlated with the English after shifting it seven places to the right.
  Notice how the tall bars at KLM moves to RST.}
  \label{figure:freqs}
\end{figure}

By shifting the alphabets, which basically means moving horizontally or
vertically in the Vigenère table, we can get a better correlation.

Finally, I recombined each column back to its original --- the reverse of the
operation mentioned earlier. This produced the plaintext directly.

After I had the plaintext, I recovered the key by simply decrypting the
ciphertext with the plaintext. That produced the repeated key, which I cut off
at the known length.

\section{Part II --- Simplified DES (SDES)}

The two first tasks were to implement SDES and TripleSDES (3SDES) and complete
a table of plain- and ciphertexts. Both results are shown in table
\vref{table:sdes}.

\begin{table}
  \centering
  \begin{tabular}{@{}llll@{}}
    \toprule
    \multicolumn{4}{c}{\textbf{Task 1}} \\
    Key & &
    Plaintext &
    Ciphertext \\
    \midrule
    \texttt{0000000000} & & \texttt{00000000} & \texttt{\textbf{11110000}} \\
    \texttt{0000011111} & & \texttt{11111111} & \texttt{\textbf{11100001}} \\
    \texttt{0010011111} & & \texttt{11111100} & \texttt{\textbf{10011101}} \\
    \texttt{0010011111} & & \texttt{10100101} & \texttt{\textbf{10010000}} \\
    \texttt{1111111111} & & \texttt{\textbf{11111111}} & \texttt{00001111} \\
    \texttt{0000011111} & & \texttt{\textbf{00000000}} & \texttt{01000011} \\
    \texttt{1000101110} & & \texttt{\textbf{00111000}} & \texttt{00011100} \\
    \texttt{1000101110} & & \texttt{\textbf{00001100}} & \texttt{11000010} \\
    \toprule
    \multicolumn{4}{c}{\textbf{Task 2}} \\
      Key 1 &
      Key 2 &
      Plaintext &
      Ciphertext \\
    \midrule
             \texttt{1000101110} &
             \texttt{0110101110} &
               \texttt{11010111} &
       \texttt{\textbf{10111001}} \\

            \texttt{1000101110} &
            \texttt{0110101110} &
              \texttt{10101010} &
      \texttt{\textbf{11100100}} \\

            \texttt{1111111111} &
            \texttt{1111111111} &
              \texttt{00000000} &
      \texttt{\textbf{11101011}} \\

            \texttt{0000000000} &
            \texttt{0000000000} &
              \texttt{01010010} &
      \texttt{\textbf{10000000}} \\

            \texttt{1000101110} &
            \texttt{0110101110} &
      \texttt{\textbf{11111101}} &
              \texttt{11100110} \\

             \texttt{1011101111} &
             \texttt{0110101110} &
       \texttt{\textbf{01001111}} &
               \texttt{01010000} \\

            \texttt{1111111111} &
            \texttt{1111111111} &
      \texttt{\textbf{10101010}} &
              \texttt{00000100} \\

            \texttt{0000000000} &
            \texttt{0000000000} &
      \texttt{\textbf{00000000}} &
              \texttt{11110000} \\
    \bottomrule
  \end{tabular}
  \caption{Results of SDES and TripleSDES encryption and decryption.}
  \label{table:sdes}
\end{table}

\subsection{Task 3: Cracking SDES and TripleDES}

\paragraph{SDES encrypted file} named \texttt{cxt1.txt} was decrypted with the
following result:

\paragraph{Key} \texttt{1111101010} or \texttt{0x3ea}

\paragraph{Plaintext}
\texttt{simplifieddesisnotsecureenoughtoprovideyousufficientsecurity}

\begin{center}
\textit{Simplified DES is not secure enough to provide you sufficient security.}
\end{center}

Since the key is only 10 bits, I brute-forced it. I started with a set of all
the possible 1023 keys, then for each byte, I tried to decrypt with each key.
Assuming that the output text would be ASCII, I checked if the output byte was
within the printable ASCII range of 32--126. If it wasn't, the key was
immediately removed from the set. When the set contained a single key, I
stopped and printed the output.

\paragraph{TripleSDES encrypted file} named \texttt{cxt2.txt}

\paragraph{Key 1} 1002 / 0x3ea / 0b1111101010 (same as the above key)
\paragraph{Key 2} 351 / 0x15f / 0b1111101010
\paragraph{Plaintext}
\texttt{simplifieddesisnotsecureenoughtoprovideyousufficientsecurity} (same as
above)

This time, there are two 10-bit keys, giving the 20-bit space of possible keys.
I used the exact same strategy as above, but used a JIT-compiler to make it
break the ciphertext in around 2.5 seconds (using pypy).

The filtering mechanism was exactly the same: Remove keys that do not provide
output in the possible output space.

The running time was slower, but since it still ran in reasonable time and gave
the correct result, I didn't employ any smarter way to break it. A possible way
to do that would be to split up the three-part decryption into distinct parts.
At least the last step, decrypting the final part, I could have filtered that
alone on all possible input bytes. However, that would mean I would have to
traverse all 10-bit keys on all 8-bit inputs, so it would do it in $2^{18}$.

An alternative route would be to use a language like C to break it, which would
not be smarter in any way, just purely faster.

Had the task been to search a larger space, I would surely have figured out a
smarter way to break it.

\section{Conclusion}

A short paragraph that restates the objective from your introduction and
relates it to your results and discussion describes any future improvements on
your techniques that you would recommend.

\bibliography{references}
\bibliographystyle{ieeetr}

\end{document}
